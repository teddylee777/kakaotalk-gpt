import streamlit as st
from langchain_core.messages import ChatMessage
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import (
    RunnableLambda,
    RunnablePassthrough,
    ConfigurableField,
)
from langchain_community.document_transformers import LongContextReorder
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma, FAISS
import kakaotalk_loader as kakao
import prompt as prmpt
import embeddings
import retriever
import tempfile
from utils import print_messages, StreamHandler

st.set_page_config(page_title="ì¹´í†¡GPT", page_icon="ğŸ’¬")
st.title("ì¹´í†¡GPTğŸ’¬")
st.markdown(
    """by [í…Œë””ë…¸íŠ¸](https://www.youtube.com/c/teddynote). ì†ŒìŠ¤ì½”ë“œ í™œìš©ì‹œ ë°˜ë“œì‹œ **ì¶œì²˜**ë¥¼ ë°í˜€ì£¼ì„¸ìš”ğŸ™"""
)

if "messages" not in st.session_state:
    st.session_state["messages"] = []

with st.sidebar:
    openai_api_key = st.text_input(
        "ğŸ”‘ OpenAI API í‚¤",
        type="password",
    )
    if openai_api_key:
        st.session_state["OPENAI_API_KEY"] = openai_api_key
    st.markdown(
        "ğŸ“Œ CSVíŒŒì¼ ë‹¤ìš´ë¡œë“œ ë°©ë²•\n\n`ì±„íŒ…ë°©`-`ìš°ì¸¡ìƒë‹¨ í–„ë²„ê±°ë©”ë‰´`-`ì±„íŒ…ë°© ì„¤ì •`-`ëŒ€í™” ë‚´ìš© ê´€ë¦¬`-`ëŒ€í™” ë‚´ìš© ì €ì¥`"
    )
    kakaotalk_file = st.file_uploader("ğŸ“„ ì¹´í†¡ CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])
    if kakaotalk_file:
        if "OPENAI_API_KEY" not in st.session_state:
            st.info("OpenAI API Keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            st.session_state["kakaotalk_file"] = kakaotalk_file

if "kakaotalk_file" in st.session_state and "retriever" not in st.session_state:
    with st.sidebar:
        with st.status("íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤ ğŸ§‘â€ğŸ’»ğŸ‘©â€ğŸ’»", expanded=True) as status:
            with tempfile.NamedTemporaryFile() as f:
                f.write(st.session_state["kakaotalk_file"].read())
                f.flush()
                # ì¹´ì¹´ì˜¤í†¡ ë¡œë”
                loader = kakao.KaKaoTalkLoader(f.name, encoding="utf8")

                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=500, chunk_overlap=0
                )
                documents = loader.load_and_split(text_splitter=text_splitter)
                st.write("â‘  ì„ë² ë”© ìƒì„±")
                status.update(label="â‘  ì„ë² ë”©ì„ ìƒì„± ì¤‘..ğŸ”¥", state="running")
                # Embedding ìƒì„±
                embeddings = embeddings.embedding_factory(
                    api_key=st.session_state["OPENAI_API_KEY"]
                )

                st.write("â‘¡ DB ì¸ë±ì‹±")
                status.update(label="â‘¡ DB ì¸ë±ì‹± ìƒì„± ì¤‘..ğŸ”¥", state="running")
                # VectorStore ìƒì„±
                faiss = FAISS.from_documents(documents, embeddings["faiss"])
                chroma = Chroma.from_documents(documents, embeddings["chroma"])

                st.write("â‘¢ Retriever ìƒì„±")
                status.update(label="â‘¢ Retriever ìƒì„± ì¤‘..ğŸ”¥", state="running")
                # FAISSRetriever ìƒì„±
                faiss_retriever = retriever.FAISSRetrieverFactory(faiss).create(
                    search_kwargs={"k": 30},
                )

                # SelfQueryRetriever ìƒì„±
                self_query_retriever = retriever.SelfQueryRetrieverFactory(
                    chroma
                ).create(
                    model="gpt-4-turbo-preview",
                    temperature=0,
                    api_key=st.session_state["OPENAI_API_KEY"],
                    search_kwargs={"k": 30},
                )

                # ì•™ìƒë¸” retrieverë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
                ensemble_retriever = retriever.EnsembleRetrieverFactory(None).create(
                    retrievers=[faiss_retriever, self_query_retriever],
                    weights=[0.4, 0.6],
                )
                reordering = LongContextReorder()

                combined_retriever = ensemble_retriever | RunnableLambda(
                    reordering.transform_documents
                )
                st.session_state["retriever"] = combined_retriever
                st.write("ì™„ë£Œ âœ…")
                status.update(label="ì™„ë£Œ âœ…", state="complete", expanded=False)
        st.markdown(f'ğŸ’¬ `{st.session_state["kakaotalk_file"].name}`')
        st.markdown(
            "ğŸ””ì°¸ê³ \n\n**ìƒˆë¡œìš´ ì¹´í†¡ íŒŒì¼** ë¡œ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë ¤ë©´, `ìƒˆë¡œê³ ì¹¨` í›„ ì§„í–‰í•´ ì£¼ì„¸ìš”"
        )


# ì´ì „ ëŒ€í™”ê¸°ë¡ì„ ì¶œë ¥í•´ ì£¼ëŠ” ì½”ë“œ
print_messages()


if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."):
    if "OPENAI_API_KEY" not in st.session_state:
        st.info("OpenAI API Keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    elif "retriever" not in st.session_state:
        st.info("KakaoTalk CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    else:
        # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©
        st.chat_message("user").write(f"{user_input}")
        st.session_state["messages"].append(
            ChatMessage(role="user", content=user_input)
        )

        # AIì˜ ë‹µë³€
        with st.chat_message("assistant"):
            stream_handler = StreamHandler(st.empty())

            llm = ChatOpenAI(
                model_name="gpt-4-turbo-preview",
                temperature=0,
                streaming=True,
                callbacks=[stream_handler],
                api_key=st.session_state["OPENAI_API_KEY"],
            ).configurable_alternatives(
                ConfigurableField(id="llm"),
                default_key="gpt4",
                gpt3=ChatOpenAI(
                    model="gpt-3-turbo",
                    temperature=0,
                    streaming=True,
                    callbacks=[stream_handler],
                    api_key=st.session_state["OPENAI_API_KEY"],
                ),
            )

            chain = (
                {
                    "context": st.session_state["retriever"],
                    "question": RunnablePassthrough(),
                }
                | prmpt.rag_prompt()
                | llm
                | StrOutputParser()
            )

            response = chain.invoke(
                user_input,
            )
            st.session_state["messages"].append(
                ChatMessage(role="assistant", content=response)
            )
